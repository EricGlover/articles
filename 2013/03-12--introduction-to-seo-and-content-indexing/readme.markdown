<sub>&#x1F6A8; <strong>Autogenerated!</strong> See <a href="https://github.com/ponyfoo/articles/tree/noindex/contributing.markdown"><code>contributing.markdown</code></a> for details. See also: <a href="https://ponyfoo.com/articles/introduction-to-seo-and-content-indexing">web version</a>.</sub>

<a href="https://ponyfoo.com/articles/introduction-to-seo-and-content-indexing"><div></div></a>

<h1>Introduction to SEO and Content Indexing</h1>

<p><kbd>seo</kbd> <kbd>ajax</kbd></p>

<blockquote><p>Just a few days ago, <a href="http://google.com/" target="_blank">Google</a> started indexing <a href="http://blog.ponyfoo.com/" target="_blank">this blog</a>, and it&#x2019;s <em>just starting to show up</em> in their search results. I wanted to go over the steps I took to make a <em>&#x2026;</em></p></blockquote>

<div><p>Just a few days ago, <a href="http://google.com/" target="_blank">Google</a> started indexing <a href="http://blog.ponyfoo.com/" target="_blank">this blog</a>, and it&#x2019;s <em>just starting to show up</em> in their search results. I wanted to go over the steps I took to make a <em>good impression</em> on them.</p></div>

<div></div>

<div><p>I must admit that <em>I&#x2019;m no expert on SEO</em>, <strong>I just read a lot</strong>, and I think I&#x2019;ve come to amass a <em>good sense</em> in what makes a site relevant in the eyes of web crawlers such as <a href="http://google.com/" target="_blank">Google</a>.</p></div>

<div><h1 id="semantic-html-and-content-relevance">Semantic HTML and Content Relevance</h1> <p>The absolute first step was <em>semantic markup</em>. That is, using <strong>HTML 5</strong> tags, such as <code class="md-code md-code-inline">&lt;article&gt;</code>, <code class="md-code md-code-inline">&lt;section&gt;</code>, <code class="md-code md-code-inline">&lt;header&gt;</code>, <code class="md-code md-code-inline">&lt;footer&gt;</code> and so on. For a <em>full list of HTML 5 tags</em>, <a href="https://developer.mozilla.org/en-US/docs/HTML/HTML5/HTML5_element_list" target="_blank" aria-label="HTML 5 Tag List">visit MDN</a>.</p> <p>This helps crawlers assign <strong>weight</strong> (importance) to each piece of HTML in your page. It makes your pages <em>future-proof</em>, meaning that when and if crawlers start giving more importance to semantic markup, you will be ready for it. Additionaly, <em>it makes your CSS more semantic, too</em>, which can&#x2019;t hurt.</p> <p>Always make sure your content is relevant to the keywords you aspire to be found for, <em>don&#x2019;t just spit a bunch of keywords</em> onto your site and expect good things to happen. Your visitors won&#x2019;t take your site seriously if you do that, <strong>which is your end goal anyways</strong>.</p> <blockquote> <p>What is the point in being <em>well-ranked</em> if your visitors don&#x2019;t <em>consume or appreciate</em> the contents of your site?</p> </blockquote> <h1 id="analytics">Analytics</h1> <p>The second step I took was adding <a href="http://www.google.com/analytics/" target="_blank" aria-label="Google Web Analytics">Google Analytics</a> to my solution. I later went on and added a couple of other services: <a href="http://clicky.com/" target="_blank" aria-label="Clicky Web Analytics">Clicky</a> and [New Relic](<a href="http://newrelic.com/" target="_blank">http://newrelic.com/</a> &quot;New Relic Application Monitoring), to improve my analytics and have at least some sort of <em>uptime monitoring</em>. All these services are really easy to include <em>effortlessly</em> in your application, and they provide <strong>a lot of value</strong>.</p> <p>Analytics can tell you <em>what pages</em> users land on, what pages are the <em>most linked to</em>, where your users <em>come from</em>, as well as <em>how your users behave</em> and what they are looking for. In summary, it&#x2019;s really important to know what&#x2019;s going on with your site in the grand scheme of things, and figure out how to proceed, and analytics tools are a <em>great way</em> to accomplish just that.</p> <p>You also definitely want to sign up for <a href="https://www.google.com/webmasters/" target="_blank" aria-label="Google Webmaster Tools">Webmaster Tools</a>, which will be <strong>immensely helpful</strong> in putting it all together, and will also help you track your index status closely.</p> <h1 id="ajax-crawling">AJAX Crawling</h1> <p>This is the most complex step I took. Since this site is entirely AJAX, <em>meaning users navigating only load the site once</em>, the page is for all intents and purposes <em>static</em>, meaning that no matter what page you go to, you get <em>the same HTML</em>, and then JavaScript takes care of displaying the appropriate view. This is clearly a <strong>dealbreaking issue</strong> for web scrapers, because they cannot index your site if <em>all your pages look the same</em>.</p> <blockquote> <p>Without a proper AJAX crawling strategy, any other efforts to improve SEO are <strong>utterly useless</strong>. You need <em>a good crawling strategy</em> that allows search engines to get the content a regular surfer would find in each page.</p> </blockquote> <p>The desired behavior would, then, be some sort of reflection of this <em>mockup</em>:</p> <p><a href="https://i.imgur.com/JdHh6JF.png" target="_blank"><img alt="crawler.png" title="Desired behavior" class="" src="https://i.imgur.com/JdHh6JF.png"></a></p> <h3 id="implementation">Implementation</h3> <p>In my research, I figured out a <a href="http://zombie.labnotes.org/" target="_blank" aria-label="Zombie.js headless browser">headless browser</a> was the way to go. A <strong>headless browser</strong> is basically a way to make a request to a page <em>and execute any JavaScript</em> in it, without resorting to a <em>full-fledged</em> web browser. This would allow me to <strong>transparently</strong> serve web crawlers with static versions of the dynamic pages on my blog, without having to resort to <em>obscure techniques</em> or manually editing the static versions of the site.</p> <p>Once I had this down, it was just a matter of adding a little helper to <em>every single <strong>GET</strong> route</em> to handle crawler requests differently. If a request comes in and it matches one of the known web crawler user agents, a <em>second request</em> is triggered on behalf of the crawler, against the same resource, and through the headless browser.</p> <p>After waiting for all the JavaScript to get executed, and after a little cleanup (since the page is static, it makes sense to me to <em>remove all script tags</em> before serving it), we are ready to serve this view to the crawler agent.</p> <p>One last step if you care about performance is dumping this into a file cache that is relatively <strong>short-lived</strong> (meaning you&#x2019;ll <em>invalidate that cached page</em> if a determined amount of time elapses), in order to save yourself a web request in subsequent calls made by a crawler agent against that resource.</p> <p>If you are curious about how to implement this, <a href="https://github.com/bevacqua/ponyfoo/blob/v0.2/src/logic/zombie.js" target="_blank" aria-label="Crawler AJAX Support Implementation">here is my take for this blog</a>, it is implemented in Node.</p> <p>Note that <em>this might not be the latest version</em>. It&#x2019;s the one contained in the <strong>v0.2</strong> tag. Although I don&#x2019;t expect to change it much.</p> <blockquote> <p>Once that&#x2019;s settled, and working, you can do awesome stuff such as updating your <code class="md-code md-code-inline">&lt;meta&gt;</code> tags through JavaScript, and the web crawlers will pick up on it!</p> </blockquote> <h1 id="metadata">Metadata</h1> <p>Metadata is <strong>crucial</strong> to being <em>well-positioned</em> in search results. There are lots of meta content you can enrich your site with. I&#x2019;ll talk about some of the metadata you can include, particularly about what <em>I</em> have chosen to include.</p> <p><em>Use <code class="md-code md-code-inline">&lt;meta&gt;</code> tags</em></p> <p>The single most important <code class="md-code md-code-inline">&lt;meta&gt;</code> tag is <code class="md-code md-code-inline">&lt;meta name=&apos;description&apos; content=&apos;...&apos;&gt;</code>. This tag should uniquely describe each page in your site. Meaning different description tags should never have the same <em>content</em> attribute value. You should keep the description tag <em>brief</em>, though <em>not too short</em>, since it&#x2019;ll be the description users will get when your page gets <em>a search results impression</em>.</p> <p>The <code class="md-code md-code-inline">&lt;meta name=&apos;keywords&apos; content=&apos;...&apos;&gt;</code> tag is much discussed, and seems to have been <a href="http://googlewebmastercentral.blogspot.com.ar/2009/09/google-does-not-use-keywords-meta-tag.html" target="_blank" aria-label="Google does not use the keywords meta tag">mostly irrelevant</a> for a while now, but <em>it won&#x2019;t do any harm</em> should you decide to include it.</p> <p><em>Provide <a href="http://ogp.me/" target="_blank" aria-label="Open Graph protocol">Open Graph</a> metadata</em></p> <p><strong>Open Graph</strong> is a set of <em>meta properties</em> pushed by <a href="https://developers.facebook.com/" target="_blank" aria-label="Facebook Developers">Facebook</a>. These are mostly useful <em>when sharing links</em> to your site on social networks. Try to include a relevant thumbnail, the actual title of each page, and an appropriate description of that page. You definitely should include these in your website if you care about <strong>SEO</strong>.</p> <p><em>Implement <a href="http://schema.org/" target="_blank" aria-label="Schema.org vocabulary">Schema.org</a> microdata</em></p> <p><strong><a href="http://schema.org/" target="_blank">Schema.org</a></strong> microdata allows you to mark up your site with attributes indicating what the content might be. You can read more about microdata on <a href="http://support.google.com/webmasters/bin/answer.py?hl=en&amp;answer=176035" target="_blank" aria-label="About microdata">Google</a>. This will help <a href="http://google.com/" target="_blank" aria-label="Google Search Engine">Google</a> display your site in search results, and figure the types of content published in your site.</p> <h1 id="search-engine-support">Search engine Support</h1> <p>There are at least a couple of ways to <em>help search engines</em> get on the right tracks when <em>indexing your website</em>. You should take full advantage of these.</p> <p><em>Provide a <a href="http://www.robotstxt.org/" target="_blank" aria-label="robots.txt explained">robots.txt</a> file</em></p> <p>There isn&#x2019;t <em>a lot</em> to say about <a href="http://www.robotstxt.org/" target="_blank" aria-label="robots.txt explained">robots.txt</a>, don&#x2019;t <em>depend</em> on crawlers honoring your rules, but rather make your site follow the <a href="http://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" aria-label="Representational State Transfer - REST">REST guidelines</a> to the letter, so that your <em>unsuspecting data</em> doesn&#x2019;t get <strong>ravaged</strong> by a curious spider.</p> <p><em>Publish a <a href="http://www.sitemaps.org/" target="_blank" aria-label="sitemaps.org">sitemap.xml</a></em></p> <p>By submitting a sitemap, you can give hints to a web crawler about how you value your site&#x2019;s content, and help it index your website. You can read more about sitemaps on <a href="http://support.google.com/webmasters/bin/answer.py?hl=en&amp;answer=156184" target="_blank" aria-label="About Sitemaps">Google</a> or <a href="http://www.sitemaps.org/" target="_blank" aria-label="sitemaps.org">here</a>.</p> <h1 id="alternative-traffic-sources">Alternative traffic sources</h1> <p>It is always wise to provide users with <em>alternative means</em> of accessing your website&#x2019;s content.</p> <p><em>Implement OpenSearch Protocol</em></p> <p>A while back I talked about <a href="https://ponyfoo.com/2013/02/05/implementing-opensearch" aria-label="Implementing OpenSearch">implementing OpenSearch</a>. This allows users to <em>search</em> your site <em>directly</em> from their browser&#x2019;s <em>address bar</em>.</p> <p><em>Publish Feeds</em></p> <p>I don&#x2019;t think feeds such as <a href="http://en.wikipedia.org/wiki/RSS" target="_blank" aria-label="Really Simple Syndication">RSS</a> need an introduction. I <em>recommend</em> to publish at least a single feed to your site&#x2019;s content. Keeping it up to date is <em>just as important</em>.</p></div>
